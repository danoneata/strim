import pdb
import random

import h5py
import numpy as np
import streamlit as st

from sacrebleu import BLEU
from toolz import partition_all

from strim.data import Flickr8kDataset


# MODELS = ["blip-base", "blip-large", "blip2-opt-2.7b", "git-base-coco", "git-large-coco"]
# GENERATIONS = ["topk", "sample", "diverse"]

MODELS = ["blip-large", "blip2-opt-2.7b", "git-large-coco"]
GENERATIONS = ["topk", "sample1", "diverse"]
URL_RESULTS = "https://docs.google.com/spreadsheets/d/1djZn7Nv0EFo8Ueivl--xyu0TaPrtmnmD8ZtVNQGq9RM/edit#gid=1760303189"

code_quote = lambda s: "`{}`".format(s)

st.set_page_config(layout="wide")
with st.sidebar:
    st.markdown("""
    This webpage shows the captions generated by different image captioning models ({}) and different generation strategies ({}).
    We show results for a random sample of images from the Flickr8k test set;
    refreshing the page will show a different sample of images.
    For quantitative results, see [this Google spreadsheet]({}).
    """.format(", ".join(map(code_quote, MODELS)), ", ".join(map(code_quote, GENERATIONS)), URL_RESULTS))


IMAGE_MODELS = [f"{m}-{g}" for m in MODELS for g in GENERATIONS]


def get_texts(f, path):
    return [text.decode() for text in np.array(f[path])[...]]


def bullet_list(items):
    return "\n".join("- " + item for item in items)


dataset = Flickr8kDataset(split="test")
image_key_to_captions = dataset.get_image_key_to_captions()

path_hdf5_image = "output/image-captioner/{}-flickr8k-test.h5"
hdf5_files = [h5py.File(path_hdf5_image.format(model), "r") for model in IMAGE_MODELS]


keys = list(image_key_to_captions.keys())
random.shuffle(keys)
keys = keys[:30]
# keys.insert(0, "2866254827_9a8f592017")   # example in the paper

num_cols = 3
num_models = len(IMAGE_MODELS)


fmt = lambda s: s.strip()

bleu = BLEU(lowercase=True, effective_order=True)


def compute_bleu_score(pred_text, true_texts):
    def fmt_txt(s):
        return s.replace(" .", "").lower()
    pred = fmt_txt(pred_text)
    true = [fmt_txt(c) for c in true_texts]
    return bleu.sentence_score(pred, true).score


for key in keys:
    true_captions = image_key_to_captions[key]
    path = key + "/" + "generated-captions"
    sample = {"key-image": key}

    cols = st.columns(num_cols)

    cols[0].markdown("image id: `{}`".format(key))
    cols[0].image(str(dataset.get_image_path(sample)))

    cols[1].markdown("true captions:")
    cols[1].markdown(bullet_list(true_captions))

    idxs = range(num_models)

    for group in partition_all(num_cols, idxs):
        cols = st.columns(num_cols)
        for i, col in zip(group, cols):
            generated_captions = get_texts(hdf5_files[i], path)
            blue_scores = [compute_bleu_score(caption, true_captions) for caption in generated_captions]
            lines = [f"{score:.1f} Â· {fmt(caption)}" for score, caption in zip(blue_scores, generated_captions)]
            col.markdown("`{}`:".format(IMAGE_MODELS[i]))
            col.markdown(bullet_list(lines))
            # col.markdown("---")

    st.markdown("---")


for f in hdf5_files:
    f.close()
